{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, torch:\n",
    "    print(module.__name__, module.__version__)\n",
    "    \n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:12.527334Z",
     "iopub.execute_input": "2024-05-03T04:47:12.527802Z",
     "iopub.status.idle": "2024-05-03T04:47:17.362854Z",
     "shell.execute_reply.started": "2024-05-03T04:47:12.527757Z",
     "shell.execute_reply": "2024-05-03T04:47:17.361864Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T16:11:30.417410Z",
     "start_time": "2025-02-06T16:11:24.874159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=12, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.10.0\n",
      "numpy 2.0.2\n",
      "pandas 2.2.3\n",
      "sklearn 1.6.1\n",
      "torch 2.6.0+cpu\n",
      "cpu\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 准备数据"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# 用karas有的数据集imdb，电影分类,分电影是积极的，还是消极的\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# 载入数据使用下面两个参数\n",
    "vocab_size = 10000  #词典大小，仅保留训练数据中前10000个最经常出现的单词，低频单词被舍弃\n",
    "index_from = 3  #0,1,2,3空出来做别的事\n",
    "\n",
    "# 前一万个词出现词频最高的会保留下来进行处理，后面的作为特殊字符处理，\n",
    "# 小于3的id都是特殊字符，下面代码有写\n",
    "# 需要注意的一点是取出来的词表还是从1开始的，需要做处理\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = vocab_size, index_from = index_from)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:17.364755Z",
     "iopub.execute_input": "2024-05-03T04:47:17.365247Z",
     "iopub.status.idle": "2024-05-03T04:47:34.391998Z",
     "shell.execute_reply.started": "2024-05-03T04:47:17.365218Z",
     "shell.execute_reply": "2024-05-03T04:47:34.391210Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T16:11:39.642462Z",
     "start_time": "2025-02-06T16:11:30.419416Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"train:\", len(train_data), train_labels.shape)  #25000个样本，每个样本是一段话，每个单词用一个数字表示\n",
    "print(\"test:\", len(test_data), test_labels.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:34.393563Z",
     "iopub.execute_input": "2024-05-03T04:47:34.394093Z",
     "iopub.status.idle": "2024-05-03T04:47:34.399413Z",
     "shell.execute_reply.started": "2024-05-03T04:47:34.394068Z",
     "shell.execute_reply": "2024-05-03T04:47:34.398409Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T16:11:41.821606Z",
     "start_time": "2025-02-06T16:11:41.813703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 25000 (25000,)\n",
      "test: 25000 (25000,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "#载入词表，看下词表长度，词表就像英语字典\n",
    "word_index = imdb.get_word_index()\n",
    "print(len(word_index))\n",
    "print(type(word_index))\n",
    "#词表虽然有8万多，但是我们只载入了最高频的1万词！！！！"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:34.402571Z",
     "iopub.execute_input": "2024-05-03T04:47:34.403158Z",
     "iopub.status.idle": "2024-05-03T04:47:34.535124Z",
     "shell.execute_reply.started": "2024-05-03T04:47:34.403131Z",
     "shell.execute_reply": "2024-05-03T04:47:34.534127Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T16:11:44.076444Z",
     "start_time": "2025-02-06T16:11:44.002625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88584\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 构造 word2idx 和 idx2word"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# 创建一个字典，将单词映射到索引，索引从3开始，以避免与特殊字符的索引冲突\n",
    "word2idx = {word: idx + 3 for word, idx in word_index.items()}\n",
    "\n",
    "word2idx.update({\n",
    "    \"[PAD]\": 0,     # 填充 token\n",
    "    \"[BOS]\": 1,     # 句子开始 token\n",
    "    \"[UNK]\": 2,     # 未知单词 token\n",
    "    \"[EOS]\": 3,     # 句子结束 token\n",
    "})\n",
    "\n",
    "# 创建一个反向字典，将索引映射回单词，便于从索引序列重建文本\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:34.536374Z",
     "iopub.execute_input": "2024-05-03T04:47:34.536752Z",
     "iopub.status.idle": "2024-05-03T04:47:34.579550Z",
     "shell.execute_reply.started": "2024-05-03T04:47:34.536716Z",
     "shell.execute_reply": "2024-05-03T04:47:34.578607Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T16:11:46.665021Z",
     "start_time": "2025-02-06T16:11:46.632236Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# 统计训练数据中每个文本长度的分布情况\n",
    "length_collect = {}\n",
    "for text in train_data:\n",
    "    length = len(text)  # 获取当前文本的长度\n",
    "    # 将当前长度加入字典，如果长度已存在则增加计数，否则初始化为1\n",
    "    length_collect[length] = length_collect.get(length, 0) + 1\n",
    "    \n",
    "# 设置最大长度阈值，超过这个长度的文本将被截断或填充\n",
    "MAX_LENGTH = 500\n",
    "\n",
    "# 绘制文本长度分布的柱状图\n",
    "plt.bar(length_collect.keys(), length_collect.values())\n",
    "# 在图中标出设定的最大长度\n",
    "plt.axvline(MAX_LENGTH, label=\"max length\", c=\"gray\", ls=\":\")\n",
    "plt.legend()  # 显示图例\n",
    "plt.show()  # 显示图表"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:34.580697Z",
     "iopub.execute_input": "2024-05-03T04:47:34.581037Z",
     "iopub.status.idle": "2024-05-03T04:47:36.765733Z",
     "shell.execute_reply.started": "2024-05-03T04:47:34.581009Z",
     "shell.execute_reply": "2024-05-03T04:47:36.764837Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T16:11:50.036229Z",
     "start_time": "2025-02-06T16:11:48.804549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, word2idx, idx2word, max_length=500, pad_idx=0, bos_idx=1, eos_idx=3, unk_idx=2):\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.max_length = max_length\n",
    "        self.pad_idx = pad_idx\n",
    "        self.bos_idx = bos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.unk_idx = unk_idx\n",
    "    \n",
    "    def encode(self, text_list, padding_first=False):\n",
    "        \"\"\"如果padding_first == True，则padding加载前面，否则加载后面\"\"\"\n",
    "        max_length = min(self.max_length, 2 + max([len(text) for text in text_list]))\n",
    "        indices_list = []\n",
    "        for text in text_list:\n",
    "            indices = [self.bos_idx] + [self.word2idx.get(word, self.unk_idx) for word in text[:max_length-2]] + [self.eos_idx]\n",
    "            if padding_first:\n",
    "                indices = [self.pad_idx] * (max_length - len(indices)) + indices\n",
    "            else:\n",
    "                indices = indices + [self.pad_idx] * (max_length - len(indices))\n",
    "            indices_list.append(indices)\n",
    "        return torch.tensor(indices_list)\n",
    "    \n",
    "    \n",
    "    def decode(self, indices_list, remove_bos=True, remove_eos=True, remove_pad=True, split=False):\n",
    "        text_list = []\n",
    "        for indices in indices_list:\n",
    "            text = []\n",
    "            for index in indices:\n",
    "                word = self.idx2word.get(index, \"[UNK]\")\n",
    "                if remove_bos and word == \"[BOS]\":\n",
    "                    continue\n",
    "                if remove_eos and word == \"[EOS]\":\n",
    "                    break\n",
    "                if remove_pad and word == \"[PAD]\":\n",
    "                    break\n",
    "                text.append(word)\n",
    "            text_list.append(\" \".join(text) if not split else text)\n",
    "        return text_list\n",
    "    \n",
    "\n",
    "tokenizer = Tokenizer(word2idx=word2idx, idx2word=idx2word)\n",
    "raw_text = [\"hello world\".split(), \"tokenize text datas with batch\".split(), \"this is a test\".split()]\n",
    "indices = tokenizer.encode(raw_text, padding_first=True)\n",
    "decode_text = tokenizer.decode(indices.tolist(), remove_bos=False, remove_eos=False, remove_pad=False)\n",
    "print(\"raw text\")\n",
    "for raw in raw_text:\n",
    "    print(raw)\n",
    "print(\"indices\")\n",
    "for index in indices:\n",
    "    print(index)\n",
    "print(\"decode text\")\n",
    "for decode in decode_text:\n",
    "    print(decode)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:36.767290Z",
     "iopub.execute_input": "2024-05-03T04:47:36.767595Z",
     "iopub.status.idle": "2024-05-03T04:47:36.811355Z",
     "shell.execute_reply.started": "2024-05-03T04:47:36.767569Z",
     "shell.execute_reply": "2024-05-03T04:47:36.810435Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T16:11:52.994060Z",
     "start_time": "2025-02-06T16:11:52.980431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw text\n",
      "['hello', 'world']\n",
      "['tokenize', 'text', 'datas', 'with', 'batch']\n",
      "['this', 'is', 'a', 'test']\n",
      "indices\n",
      "tensor([   0,    0,    0,    1, 4825,  182,    3])\n",
      "tensor([    1,     2,  3004,     2,    19, 19233,     3])\n",
      "tensor([   0,    1,   14,    9,    6, 2181,    3])\n",
      "decode text\n",
      "[PAD] [PAD] [PAD] [BOS] hello world [EOS]\n",
      "[BOS] [UNK] text [UNK] with batch [EOS]\n",
      "[PAD] [BOS] this is a test [EOS]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# 看看训练集的数据\n",
    "tokenizer.decode(train_data[:2], remove_bos=False, remove_eos=False, remove_pad=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:36.812516Z",
     "iopub.execute_input": "2024-05-03T04:47:36.812799Z",
     "iopub.status.idle": "2024-05-03T04:47:36.819435Z",
     "shell.execute_reply.started": "2024-05-03T04:47:36.812774Z",
     "shell.execute_reply": "2024-05-03T04:47:36.818339Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T16:11:57.631258Z",
     "start_time": "2025-02-06T16:11:57.623258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[BOS] this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert [UNK] is an amazing actor and now the same being director [UNK] father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for [UNK] and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also [UNK] to the two little boy's that played the [UNK] of norman and paul they were just brilliant children are often left out of the [UNK] list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\",\n",
       " \"[BOS] big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal [UNK] the hair is big lots of boobs [UNK] men wear those cut [UNK] shirts that show off their [UNK] sickening that men actually wore them and the music is just [UNK] trash that plays over and over again in almost every scene there is trashy music boobs and [UNK] taking away bodies and the gym still doesn't close for [UNK] all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集与 DataLoader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, data, labels, remain_length=True):\n",
    "        if remain_length:\n",
    "            self.data = tokenizer.decode(data, remove_bos=False, remove_eos=False, remove_pad=False)\n",
    "        else:\n",
    "            # 缩减一下数据\n",
    "            self.data = tokenizer.decode(data)\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        return text, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "def collate_fct(batch):\n",
    "    text_list = [item[0].split() for item in batch]\n",
    "    label_list = [item[1] for item in batch]\n",
    "    # 这里使用 padding first\n",
    "    text_list = tokenizer.encode(text_list, padding_first=True).to(dtype=torch.int)\n",
    "    return text_list, torch.tensor(label_list).reshape(-1, 1).to(dtype=torch.float)\n",
    "\n",
    "\n",
    "# 用RNN，缩短序列长度\n",
    "train_ds = IMDBDataset(train_data, train_labels, remain_length=False)\n",
    "test_ds = IMDBDataset(test_data, test_labels, remain_length=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:36.820601Z",
     "iopub.execute_input": "2024-05-03T04:47:36.820915Z",
     "iopub.status.idle": "2024-05-03T04:47:42.935725Z",
     "shell.execute_reply.started": "2024-05-03T04:47:36.820890Z",
     "shell.execute_reply": "2024-05-03T04:47:42.934882Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T15:14:01.488150Z",
     "start_time": "2025-02-06T15:13:57.569576Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fct)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fct)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:42.940057Z",
     "iopub.execute_input": "2024-05-03T04:47:42.940354Z",
     "iopub.status.idle": "2024-05-03T04:47:42.945758Z",
     "shell.execute_reply.started": "2024-05-03T04:47:42.940327Z",
     "shell.execute_reply": "2024-05-03T04:47:42.944620Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T15:14:01.510822Z",
     "start_time": "2025-02-06T15:14:01.498219Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 定义模型"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim=16, hidden_dim=64, vocab_size=vocab_size, num_layers=1, bidirectional=False):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embeding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.layer = nn.Linear(hidden_dim * (2 if bidirectional else 1), hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # [bs, seq length]\n",
    "        x = self.embeding(x)\n",
    "        # [bs, seq length, embedding_dim] -> shape [bs, embedding_dim, seq length]\n",
    "        seq_output, (hidden, cell) = self.lstm(x)\n",
    "        # [bs, seq length, hidden_dim], [*, bs, hidden_dim]\n",
    "        x = seq_output[:, -1, :]\n",
    "        # 取最后一个时间步的输出 (这也是为什么要设置padding_first=True的原因)\n",
    "        x = self.layer(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "sample_inputs = torch.randint(0, vocab_size, (2, 128))\n",
    "    \n",
    "print(\"{:=^80}\".format(\" 一层单向 LSTM \"))       \n",
    "for key, value in LSTM().named_parameters():\n",
    "    print(f\"{key:^40}paramerters num: {np.prod(value.shape)}\")\n",
    "\n",
    "    \n",
    "print(\"{:=^80}\".format(\" 一层双向 LSTM \"))       \n",
    "for key, value in LSTM(bidirectional=True).named_parameters():\n",
    "    print(f\"{key:^40}paramerters num: {np.prod(value.shape)}\")\n",
    "\n",
    "    \n",
    "print(\"{:=^80}\".format(\" 两层单向 LSTM \"))       \n",
    "for key, value in LSTM(num_layers=2).named_parameters():\n",
    "    print(f\"{key:^40}paramerters num: {np.prod(value.shape)}\")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:42.947030Z",
     "iopub.execute_input": "2024-05-03T04:47:42.947353Z",
     "iopub.status.idle": "2024-05-03T04:47:42.981775Z",
     "shell.execute_reply.started": "2024-05-03T04:47:42.947327Z",
     "shell.execute_reply": "2024-05-03T04:47:42.980874Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T15:14:01.560297Z",
     "start_time": "2025-02-06T15:14:01.517853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================== 一层单向 LSTM ===================================\n",
      "            embeding.weight             paramerters num: 160000\n",
      "           lstm.weight_ih_l0            paramerters num: 4096\n",
      "           lstm.weight_hh_l0            paramerters num: 16384\n",
      "            lstm.bias_ih_l0             paramerters num: 256\n",
      "            lstm.bias_hh_l0             paramerters num: 256\n",
      "              layer.weight              paramerters num: 4096\n",
      "               layer.bias               paramerters num: 64\n",
      "               fc.weight                paramerters num: 64\n",
      "                fc.bias                 paramerters num: 1\n",
      "================================== 一层双向 LSTM ===================================\n",
      "            embeding.weight             paramerters num: 160000\n",
      "           lstm.weight_ih_l0            paramerters num: 4096\n",
      "           lstm.weight_hh_l0            paramerters num: 16384\n",
      "            lstm.bias_ih_l0             paramerters num: 256\n",
      "            lstm.bias_hh_l0             paramerters num: 256\n",
      "       lstm.weight_ih_l0_reverse        paramerters num: 4096\n",
      "       lstm.weight_hh_l0_reverse        paramerters num: 16384\n",
      "        lstm.bias_ih_l0_reverse         paramerters num: 256\n",
      "        lstm.bias_hh_l0_reverse         paramerters num: 256\n",
      "              layer.weight              paramerters num: 8192\n",
      "               layer.bias               paramerters num: 64\n",
      "               fc.weight                paramerters num: 64\n",
      "                fc.bias                 paramerters num: 1\n",
      "================================== 两层单向 LSTM ===================================\n",
      "            embeding.weight             paramerters num: 160000\n",
      "           lstm.weight_ih_l0            paramerters num: 4096\n",
      "           lstm.weight_hh_l0            paramerters num: 16384\n",
      "            lstm.bias_ih_l0             paramerters num: 256\n",
      "            lstm.bias_hh_l0             paramerters num: 256\n",
      "           lstm.weight_ih_l1            paramerters num: 16384\n",
      "           lstm.weight_hh_l1            paramerters num: 16384\n",
      "            lstm.bias_ih_l1             paramerters num: 256\n",
      "            lstm.bias_hh_l1             paramerters num: 256\n",
      "              layer.weight              paramerters num: 4096\n",
      "               layer.bias               paramerters num: 64\n",
      "               fc.weight                paramerters num: 64\n",
      "                fc.bias                 paramerters num: 1\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "4 * 16 * 64 #lstm.weight_ih_l0"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:42.982885Z",
     "iopub.execute_input": "2024-05-03T04:47:42.983224Z",
     "iopub.status.idle": "2024-05-03T04:47:42.989768Z",
     "shell.execute_reply.started": "2024-05-03T04:47:42.983190Z",
     "shell.execute_reply": "2024-05-03T04:47:42.988745Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T15:14:01.576713Z",
     "start_time": "2025-02-06T15:14:01.564311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "4* 64*64 #lstm.weight_hh_l0"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:42.991003Z",
     "iopub.execute_input": "2024-05-03T04:47:42.991308Z",
     "iopub.status.idle": "2024-05-03T04:47:42.998461Z",
     "shell.execute_reply.started": "2024-05-03T04:47:42.991280Z",
     "shell.execute_reply": "2024-05-03T04:47:42.997549Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T15:14:01.597563Z",
     "start_time": "2025-02-06T15:14:01.584282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 训练"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluating(model, dataloader, loss_fct):\n",
    "    loss_list = []\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    for datas, labels in dataloader:\n",
    "        datas = datas.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 前向计算\n",
    "        logits = model(datas)\n",
    "        loss = loss_fct(logits, labels)         # 验证集损失\n",
    "        loss_list.append(loss.item())\n",
    "        # 二分类\n",
    "        preds = logits > 0\n",
    "        pred_list.extend(preds.cpu().numpy().tolist())\n",
    "        label_list.extend(labels.cpu().numpy().tolist())\n",
    "        \n",
    "    acc = accuracy_score(label_list, pred_list)\n",
    "    return np.mean(loss_list), acc\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:42.999576Z",
     "iopub.execute_input": "2024-05-03T04:47:42.999917Z",
     "iopub.status.idle": "2024-05-03T04:47:43.091789Z",
     "shell.execute_reply.started": "2024-05-03T04:47:42.999882Z",
     "shell.execute_reply": "2024-05-03T04:47:43.091056Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T15:14:01.737145Z",
     "start_time": "2025-02-06T15:14:01.603630Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TensorBoard 可视化\n",
    "\n",
    "\n",
    "训练过程中可以使用如下命令启动tensorboard服务。\n",
    "\n",
    "```shell\n",
    "tensorboard \\\n",
    "    --logdir=runs \\     # log 存放路径\n",
    "    --host 0.0.0.0 \\    # ip\n",
    "    --port 8848         # 端口\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "class TensorBoardCallback:\n",
    "    def __init__(self, log_dir, flush_secs=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            log_dir (str): dir to write log.\n",
    "            flush_secs (int, optional): write to dsk each flush_secs seconds. Defaults to 10.\n",
    "        \"\"\"\n",
    "        self.writer = SummaryWriter(log_dir=log_dir, flush_secs=flush_secs)\n",
    "\n",
    "    def draw_model(self, model, input_shape):\n",
    "        self.writer.add_graph(model, input_to_model=torch.randn(input_shape))\n",
    "        \n",
    "    def add_loss_scalars(self, step, loss, val_loss):\n",
    "        self.writer.add_scalars(\n",
    "            main_tag=\"training/loss\", \n",
    "            tag_scalar_dict={\"loss\": loss, \"val_loss\": val_loss},\n",
    "            global_step=step,\n",
    "            )\n",
    "        \n",
    "    def add_acc_scalars(self, step, acc, val_acc):\n",
    "        self.writer.add_scalars(\n",
    "            main_tag=\"training/accuracy\",\n",
    "            tag_scalar_dict={\"accuracy\": acc, \"val_accuracy\": val_acc},\n",
    "            global_step=step,\n",
    "        )\n",
    "        \n",
    "    def add_lr_scalars(self, step, learning_rate):\n",
    "        self.writer.add_scalars(\n",
    "            main_tag=\"training/learning_rate\",\n",
    "            tag_scalar_dict={\"learning_rate\": learning_rate},\n",
    "            global_step=step,\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def __call__(self, step, **kwargs):\n",
    "        # add loss\n",
    "        loss = kwargs.pop(\"loss\", None)\n",
    "        val_loss = kwargs.pop(\"val_loss\", None)\n",
    "        if loss is not None and val_loss is not None:\n",
    "            self.add_loss_scalars(step, loss, val_loss)\n",
    "        # add acc\n",
    "        acc = kwargs.pop(\"acc\", None)\n",
    "        val_acc = kwargs.pop(\"val_acc\", None)\n",
    "        if acc is not None and val_acc is not None:\n",
    "            self.add_acc_scalars(step, acc, val_acc)\n",
    "        # add lr\n",
    "        learning_rate = kwargs.pop(\"lr\", None)\n",
    "        if learning_rate is not None:\n",
    "            self.add_lr_scalars(step, learning_rate)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:43.092913Z",
     "iopub.execute_input": "2024-05-03T04:47:43.093218Z",
     "iopub.status.idle": "2024-05-03T04:47:43.118190Z",
     "shell.execute_reply.started": "2024-05-03T04:47:43.093169Z",
     "shell.execute_reply": "2024-05-03T04:47:43.117453Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T15:14:01.912017Z",
     "start_time": "2025-02-06T15:14:01.739674Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save Best\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class SaveCheckpointsCallback:\n",
    "    def __init__(self, save_dir, save_step=5000, save_best_only=True):\n",
    "        \"\"\"\n",
    "        Save checkpoints each save_epoch epoch. \n",
    "        We save checkpoint by epoch in this implementation.\n",
    "        Usually, training scripts with pytorch evaluating model and save checkpoint by step.\n",
    "\n",
    "        Args:\n",
    "            save_dir (str): dir to save checkpoint\n",
    "            save_epoch (int, optional): the frequency to save checkpoint. Defaults to 1.\n",
    "            save_best_only (bool, optional): If True, only save the best model or save each model at every epoch.\n",
    "        \"\"\"\n",
    "        self.save_dir = save_dir\n",
    "        self.save_step = save_step\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_metrics = -1\n",
    "        \n",
    "        # mkdir\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.mkdir(self.save_dir)\n",
    "        \n",
    "    def __call__(self, step, state_dict, metric=None):\n",
    "        if step % self.save_step > 0:\n",
    "            return\n",
    "        \n",
    "        if self.save_best_only:\n",
    "            assert metric is not None\n",
    "            if metric >= self.best_metrics:\n",
    "                # save checkpoints\n",
    "                torch.save(state_dict, os.path.join(self.save_dir, \"best.ckpt\"))\n",
    "                # update best metrics\n",
    "                self.best_metrics = metric\n",
    "        else:\n",
    "            torch.save(state_dict, os.path.join(self.save_dir, f\"{step}.ckpt\"))\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:43.119248Z",
     "iopub.execute_input": "2024-05-03T04:47:43.119557Z",
     "iopub.status.idle": "2024-05-03T04:47:43.129100Z",
     "shell.execute_reply.started": "2024-05-03T04:47:43.119532Z",
     "shell.execute_reply": "2024-05-03T04:47:43.128085Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T15:14:01.922398Z",
     "start_time": "2025-02-06T15:14:01.914036Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Early Stop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class EarlyStopCallback:\n",
    "    def __init__(self, patience=5, min_delta=0.01):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            patience (int, optional): Number of epochs with no improvement after which training will be stopped.. Defaults to 5.\n",
    "            min_delta (float, optional): Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute \n",
    "                change of less than min_delta, will count as no improvement. Defaults to 0.01.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_metric = -1\n",
    "        self.counter = 0\n",
    "        \n",
    "    def __call__(self, metric):\n",
    "        if metric >= self.best_metric + self.min_delta:\n",
    "            # update best metric\n",
    "            self.best_metric = metric\n",
    "            # reset counter \n",
    "            self.counter = 0\n",
    "        else: \n",
    "            self.counter += 1\n",
    "            \n",
    "    @property\n",
    "    def early_stop(self):\n",
    "        return self.counter >= self.patience\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:43.130506Z",
     "iopub.execute_input": "2024-05-03T04:47:43.130817Z",
     "iopub.status.idle": "2024-05-03T04:47:43.140541Z",
     "shell.execute_reply.started": "2024-05-03T04:47:43.130781Z",
     "shell.execute_reply": "2024-05-03T04:47:43.139593Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T15:14:01.936177Z",
     "start_time": "2025-02-06T15:14:01.923410Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# 训练\n",
    "def training(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    epoch, \n",
    "    loss_fct, \n",
    "    optimizer, \n",
    "    tensorboard_callback=None,\n",
    "    save_ckpt_callback=None,\n",
    "    early_stop_callback=None,\n",
    "    eval_step=500,\n",
    "    ):\n",
    "    record_dict = {\n",
    "        \"train\": [],\n",
    "        \"val\": []\n",
    "    }\n",
    "    \n",
    "    global_step = 0\n",
    "    model.train()\n",
    "    with tqdm(total=epoch * len(train_loader)) as pbar:\n",
    "        for epoch_id in range(epoch):\n",
    "            # training\n",
    "            for datas, labels in train_loader:\n",
    "                datas = datas.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # 梯度清空\n",
    "                optimizer.zero_grad()\n",
    "                # 模型前向计算\n",
    "                logits = model(datas)\n",
    "                # 计算损失\n",
    "                loss = loss_fct(logits, labels)\n",
    "                # 梯度回传\n",
    "                loss.backward()\n",
    "                # 调整优化器，包括学习率的变动等\n",
    "                optimizer.step()\n",
    "                preds = logits > 0\n",
    "            \n",
    "                acc = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())    \n",
    "                loss = loss.cpu().item()\n",
    "                # record\n",
    "                \n",
    "                record_dict[\"train\"].append({\n",
    "                    \"loss\": loss, \"acc\": acc, \"step\": global_step\n",
    "                })\n",
    "                \n",
    "                # evaluating\n",
    "                if global_step % eval_step == 0:\n",
    "                    model.eval()\n",
    "                    val_loss, val_acc = evaluating(model, val_loader, loss_fct)\n",
    "                    record_dict[\"val\"].append({\n",
    "                        \"loss\": val_loss, \"acc\": val_acc, \"step\": global_step\n",
    "                    })\n",
    "                    model.train()\n",
    "                    \n",
    "                    # 1. 使用 tensorboard 可视化\n",
    "                    if tensorboard_callback is not None:\n",
    "                        tensorboard_callback(\n",
    "                            global_step, \n",
    "                            loss=loss, val_loss=val_loss,\n",
    "                            acc=acc, val_acc=val_acc,\n",
    "                            lr=optimizer.param_groups[0][\"lr\"],\n",
    "                            )\n",
    "                \n",
    "                    # 2. 保存模型权重 save model checkpoint\n",
    "                    if save_ckpt_callback is not None:\n",
    "                        save_ckpt_callback(global_step, model.state_dict(), metric=val_acc)\n",
    "\n",
    "                    # 3. 早停 Early Stop\n",
    "                    if early_stop_callback is not None:\n",
    "                        early_stop_callback(val_acc)\n",
    "                        if early_stop_callback.early_stop:\n",
    "                            print(f\"Early stop at epoch {epoch_id} / global_step {global_step}\")\n",
    "                            return record_dict\n",
    "                    \n",
    "                # udate step\n",
    "                global_step += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\"epoch\": epoch_id})\n",
    "        \n",
    "    return record_dict\n",
    "        \n",
    "\n",
    "epoch = 20\n",
    "\n",
    "model = LSTM()\n",
    "\n",
    "# 1. 定义损失函数 采用交叉熵损失 (但是二分类)\n",
    "loss_fct = F.binary_cross_entropy_with_logits\n",
    "# 2. 定义优化器 采用 adam\n",
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 1. tensorboard 可视化\n",
    "if not os.path.exists(\"runs\"):\n",
    "    os.mkdir(\"runs\")\n",
    "tensorboard_callback = TensorBoardCallback(\"runs/imdb-lstm\")\n",
    "# tensorboard_callback.draw_model(model, [1, MAX_LENGTH])\n",
    "# 2. save best\n",
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.makedirs(\"checkpoints\")\n",
    "save_ckpt_callback = SaveCheckpointsCallback(\"checkpoints/imdb-lstm\", save_step=len(train_dl), save_best_only=True)\n",
    "# 3. early stop\n",
    "early_stop_callback = EarlyStopCallback(patience=10)\n",
    "\n",
    "\n",
    "# 如果有可用的多个GPU\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"使用多个GPU进行训练...\")\n",
    "#     model = nn.DataParallel(model)\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:43.142057Z",
     "iopub.execute_input": "2024-05-03T04:47:43.142394Z",
     "iopub.status.idle": "2024-05-03T04:47:44.062187Z",
     "shell.execute_reply.started": "2024-05-03T04:47:43.142363Z",
     "shell.execute_reply": "2024-05-03T04:47:44.061381Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T15:14:05.176040Z",
     "start_time": "2025-02-06T15:14:01.938188Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "model = model.to(device)\n",
    "start=time.time()\n",
    "record = training(\n",
    "    model, \n",
    "    train_dl, \n",
    "    test_dl, \n",
    "    epoch, \n",
    "    loss_fct, \n",
    "    optimizer, \n",
    "    tensorboard_callback=tensorboard_callback,\n",
    "    save_ckpt_callback=save_ckpt_callback,\n",
    "    early_stop_callback=early_stop_callback,\n",
    "    eval_step=len(train_dl)\n",
    "    )\n",
    "end=time.time()\n",
    "print(f'use time{end-start}')\n",
    "# 时间224s"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:47:44.063276Z",
     "iopub.execute_input": "2024-05-03T04:47:44.063556Z",
     "iopub.status.idle": "2024-05-03T04:53:29.669289Z",
     "shell.execute_reply.started": "2024-05-03T04:47:44.063531Z",
     "shell.execute_reply": "2024-05-03T04:53:29.668367Z"
    },
    "trusted": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-06T15:14:05.177046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3920 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3040fa843c80497c82cd4a4fe188d277"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#画线要注意的是损失是不一定在零到1之间的\n",
    "def plot_learning_curves(record_dict, sample_step=500):\n",
    "    # build DataFrame\n",
    "    train_df = pd.DataFrame(record_dict[\"train\"]).set_index(\"step\").iloc[::sample_step]\n",
    "    val_df = pd.DataFrame(record_dict[\"val\"]).set_index(\"step\")\n",
    "\n",
    "    # plot\n",
    "    fig_num = len(train_df.columns)\n",
    "    fig, axs = plt.subplots(1, fig_num, figsize=(5 * fig_num, 5))\n",
    "    for idx, item in enumerate(train_df.columns):    \n",
    "        axs[idx].plot(train_df.index, train_df[item], label=f\"train_{item}\")\n",
    "        axs[idx].plot(val_df.index, val_df[item], label=f\"val_{item}\")\n",
    "        axs[idx].grid()\n",
    "        axs[idx].legend()\n",
    "        # axs[idx].set_xticks(range(0, train_df.index[-1], 5000))\n",
    "        # axs[idx].set_xticklabels(map(lambda x: f\"{int(x/1000)}k\", range(0, train_df.index[-1], 5000)))\n",
    "        axs[idx].set_xlabel(\"step\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(record, sample_step=10)  #横坐标是 steps"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:53:29.670641Z",
     "iopub.execute_input": "2024-05-03T04:53:29.671094Z",
     "iopub.status.idle": "2024-05-03T04:53:30.081623Z",
     "shell.execute_reply.started": "2024-05-03T04:53:29.671059Z",
     "shell.execute_reply": "2024-05-03T04:53:30.080600Z"
    },
    "trusted": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 评估"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# dataload for evaluating\n",
    "\n",
    "# load checkpoints\n",
    "model.load_state_dict(torch.load(\"checkpoints/imdb-lstm/best.ckpt\", map_location=\"cpu\"))\n",
    "\n",
    "model.eval()\n",
    "loss, acc = evaluating(model, test_dl, loss_fct)\n",
    "print(f\"loss:     {loss:.4f}\\naccuracy: {acc:.4f}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T04:53:30.082914Z",
     "iopub.execute_input": "2024-05-03T04:53:30.083787Z",
     "iopub.status.idle": "2024-05-03T04:53:37.545678Z",
     "shell.execute_reply.started": "2024-05-03T04:53:30.083748Z",
     "shell.execute_reply": "2024-05-03T04:53:37.544622Z"
    },
    "trusted": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
